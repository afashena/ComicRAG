from pathlib import Path
import torch
from tqdm import tqdm
from transformers import DeepseekVLForConditionalGeneration, AutoProcessor
from PIL import Image
import json
from pydantic import BaseModel, ValidationError, Field
from DeepSeek_VL.inference import run_inference

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {DEVICE}")

# 1. Define the Pydantic structure
class ImageDescription(BaseModel):
    image: str = Field(description="A detailed description of the people and their mood, environment, scenery, background, and colors of objects.")
    text: str = Field(description="Description of the dialogue bubbles, text, and any onomatopoeia present in the image.")

# # 2. Load the model and processor (same as before)
# model_id = "deepseek-community/deepseek-vl-1.3b-chat"
# processor = AutoProcessor.from_pretrained(model_id)
# model = DeepseekVLForConditionalGeneration.from_pretrained(
#                                             model_id,
#                                             dtype=torch.float16,
#                                             device_map=DEVICE
#                                             )   

# 3. Load an image (example URL)
image_path = Path(r"C:\Users\BabyBunny\Documents\Data\raw_panel_images\raw_panel_images\0\37_3.jpg")
image = Image.open(image_path).convert("RGB")

def generate_img_caption(image_path: Path) -> str:
    

    placeholder_token = "<image_placeholder>" 

    # # 4. Craft the prompt to demand JSON output
    # # The JSON schema is generated by Pydantic's built-in functionality
    # json_schema = ImageDescription.model_json_schema()
    # prompt_text = f"""
    #             You are meant to describe the content of vintage comic panels. Describe the image {placeholder_token} and provide a structured description.
    #             Your structured description must be in a JSON structure mimicing the following JSON fields:
    #             {json.dumps(json_schema, indent=2)}
    #             Each field description in this schema guides what information you put in that field.
    # """

    # prompt_text = f"""You are meant to describe the content of vintage comics.
    # Describe the primary object or people in the image as well as the environment, location, and background in image {placeholder_token} in detail."""

    prompt_text = f"""You are meant to describe the content of vintage comics in JSON format.
        Describe what is in the image in the following two aspects: 

        1. {ImageDescription.model_fields['image'].description}
        2. {ImageDescription.model_fields['text'].description}

        Only use the information given in this prompt and do not add any additional assumptions or information.
        
        Output in JSON format where the first field is called 'image' and the second is 'text'. The content
        of each of those fields should be one or two sentences."""

    # 4. Run inference
    response = run_inference(prompt_text, str(image_path))

    # messages = [
    #     {
    #         "role": "user",
    #         "content": [
    #             {"type": "image", "url": image_path},
    #             {"type": "text", "text": prompt_text}
    #         ]
    #     }
    # ]

    # # 5. Generate the raw text output
    # inputs = processor(text=prompt_text, images=[image], return_tensors="pt").to(model.device)
    # with torch.no_grad():
    #     outputs = model.generate(**inputs, max_new_tokens=100, do_sample=False)
    # raw_response = processor.batch_decode(outputs, skip_special_tokens=True)[0]

    print("--- Raw Model Output (Attempting JSON) ---")
    print(response)
    print("\n" + "="*40 + "\n")

    # 6. Manually parse and validate the output using Pydantic
    try:
        # Attempt to find and load the JSON string from the response
        # Often models wrap the JSON in markdown blocks (```json ... ```)
        json_str = response.strip().strip('```json').strip('```').strip()

        data = json.loads(json_str)
        validated_data = ImageDescription(**data)

        print("--- Successfully Parsed Pydantic Object ---")
        print(validated_data.model_dump_json(indent=2))

        return validated_data.model_dump_json(indent=2)

    except (json.JSONDecodeError, ValidationError) as e:
        print(f"Failed to parse JSON or validate with Pydantic: {e}")
        print("The model output did not match the required schema.")

        return None


def caption_image_dir(image_dir: Path, output_dir: Path):
    output_dir.mkdir(parents=True, exist_ok=True)
    for image_file in tqdm(image_dir.iterdir()):
        if image_file.is_file():
            print(f"Processing image: {image_file}")
            caption = generate_img_caption(image_file)
            if caption:
                output_file = output_dir / f"{image_file.stem}_caption.json"
                with open(output_file, "w") as f:
                    f.write(caption)
                print(f"Caption saved to: {output_file}\n")
            else:
                print(f"Captioning failed for image: {image_file}\n")

if __name__ == "__main__":
    image_path = Path(r"C:\Users\BabyBunny\Documents\Data\raw_panel_images\raw_panel_images\0\37_3.jpg")
    generate_img_caption(image_path)


    image_dir = Path(r"C:\Users\BabyBunny\Documents\Data\raw_panel_images\raw_panel_images\0")
    output_dir = Path(r"C:\Users\BabyBunny\Documents\Data\panel_captions")
    caption_image_dir(image_dir, output_dir)
